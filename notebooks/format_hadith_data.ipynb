{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort and store data bookwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/ansary/work/hadith/hadith_data\"\n",
    "save_dir=\"/home/ansary/work/hadith/hadith_data_bookwise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "file_paths=[f for f in tqdm(glob(os.path.join(data_dir,\"*.json\")))]\n",
    "df=pd.DataFrame({\"file_paths\":file_paths})\n",
    "df[\"book_number\"]=df.file_paths.progress_apply(lambda x: os.path.basename(x).split(\".\")[0].split(\"-\")[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in tqdm(df.book_number.unique()):\n",
    "    bdf=df.loc[df.book_number==book]\n",
    "    paths=bdf.file_paths.tolist()\n",
    "    with open(paths[0],\"r\") as f:\n",
    "        data=json.load(f)\n",
    "    book=data['_source']['book_name']\n",
    "    os.makedirs(os.path.join(save_dir,book),exist_ok=True)\n",
    "    for _path in paths:\n",
    "        copy(_path,os.path.join(save_dir,book,os.path.basename(_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data to only matn, topic-subtopic bookwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/ansary/work/hadith/hadith_data\"\n",
    "save_dir=\"/home/ansary/work/hadith/hadith_data_bookwise_matn_topic_subtopic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "file_paths=[f for f in tqdm(glob(os.path.join(data_dir,\"*.json\")))]\n",
    "df=pd.DataFrame({\"file_paths\":file_paths})\n",
    "df[\"book_number\"]=df.file_paths.progress_apply(lambda x: os.path.basename(x).split(\".\")[0].split(\"-\")[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_filtered=['chapter','sub_chapter','matn_with_tashkeel']\n",
    "for book in tqdm(df.book_number.unique()):\n",
    "    bdf=df.loc[df.book_number==book]\n",
    "    paths=bdf.file_paths.tolist()\n",
    "    with open(paths[0],\"r\") as f:\n",
    "        data=json.load(f)\n",
    "    book=data['_source']['book_name']\n",
    "    os.makedirs(os.path.join(save_dir,book),exist_ok=True)\n",
    "    for _path in paths:\n",
    "        filtered={}\n",
    "        with open(_path,\"r\") as f:\n",
    "            data=json.load(f)['_source']\n",
    "        for k in keys_filtered:\n",
    "            filtered[k]=data[k]\n",
    "        save_json=os.path.join(save_dir,book,os.path.basename(_path))\n",
    "        with open(save_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(filtered, f, indent=2, ensure_ascii=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Hadith Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data_dir=\"/home/ansary/work/hadith/hadith_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=[f for f in tqdm(glob(os.path.join(data_dir,\"*.json\")))]\n",
    "df=pd.DataFrame({\"file_paths\":file_paths})\n",
    "df[\"book_number\"]=df.file_paths.progress_apply(lambda x: int(os.path.basename(x).split(\".\")[0].split(\"-\")[0]))\n",
    "df[\"hadith_id\"]=df.file_paths.progress_apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
    "df=df[[\"book_number\",\"hadith_id\"]]\n",
    "df.sort_values(by=[\"book_number\",\"hadith_id\"],inplace=True)\n",
    "df.to_csv(\"hadith_data_iden_bookwise.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alminasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
