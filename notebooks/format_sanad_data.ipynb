{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_data_dir=\"/home/ansary/work/hadith/chain_data_book_wise/\"\n",
    "hadith_data_dir=\"/home/ansary/work/hadith/hadith_data_bookwise/\"\n",
    "save_data_dir=\"/home/ansary/work/hadith/isnad_data_bookwise/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob \n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "os.makedirs(save_data_dir,exist_ok=True)\n",
    "hadiths=[f for f in tqdm(glob(os.path.join(hadith_data_dir,\"*/*.json\") ))]\n",
    "chains=[f for f in tqdm(glob(os.path.join(chain_data_dir,\"*/*.json\") ))]\n",
    "hdf=pd.DataFrame({\"hadith_path\":hadiths})\n",
    "cdf=pd.DataFrame({\"chain_path\":chains})\n",
    "hdf[\"hadith_id\"]=hdf[\"hadith_path\"].apply(lambda x: os.path.basename(x))\n",
    "cdf[\"hadith_id\"]=cdf[\"chain_path\"].apply(lambda x: os.path.basename(x))\n",
    "hdf[\"book\"]=hdf[\"hadith_path\"].apply(lambda x: os.path.basename(os.path.dirname(x)))\n",
    "df=hdf.merge(cdf,on=[\"hadith_id\"],how=\"outer\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_isnad(hadith_text):\n",
    "    \"\"\"\n",
    "    Extracts the isnad (chain of narrators) by removing the matn (main hadith content).\n",
    "    \n",
    "    Args:\n",
    "        hadith_text (str): The full hadith text including isnad and matn.\n",
    "    \n",
    "    Returns:\n",
    "        str: The extracted isnad text.\n",
    "    \"\"\"\n",
    "    # Parse the text as HTML\n",
    "    soup = BeautifulSoup(hadith_text, 'html.parser')\n",
    "\n",
    "    # Remove the matn tag and its contents\n",
    "    matn_tag = soup.find('a', class_='matn')\n",
    "    if matn_tag:\n",
    "        matn_tag.decompose()\n",
    "\n",
    "    # Get the isnad with narrator IDs preserved\n",
    "    isnad = str(soup)\n",
    "\n",
    "    return isnad.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def check_additional_narrators(raw_isnad, chain):\n",
    "    \"\"\"\n",
    "    Check if there are additional narrators in raw_isnad not present in chain data.\n",
    "    \n",
    "    Args:\n",
    "        raw_isnad (str): HTML string containing the isnad with narrator tags.\n",
    "        chain (dict): Dictionary of chain data with id, label, and type.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (bool, set or None) - True if additional narrators exist, with their IDs; False otherwise.\n",
    "    \"\"\"\n",
    "    # Step 1: Parse raw_isnad and extract narrator IDs\n",
    "    soup = BeautifulSoup(raw_isnad, 'html.parser')\n",
    "    rawy_tags = soup.find_all('a', class_='rawy')\n",
    "    raw_isnad_ids = [tag['id'] for tag in rawy_tags]\n",
    "    \n",
    "    # Step 2: Extract narrator IDs from chain where type is 'Narrator'\n",
    "    chain_narrator_ids = [value['id'] for value in chain.values() if value['type'] == 'Narrator']\n",
    "    \n",
    "    # Step 3: Find additional IDs using set difference\n",
    "    additional_ids = set(raw_isnad_ids) - set(chain_narrator_ids)\n",
    "    \n",
    "    # Step 4: Return result\n",
    "    if additional_ids:\n",
    "        return True, additional_ids\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import arabic_reshaper\n",
    "\n",
    "def process_hadith_text(hadith_text):\n",
    "    \"\"\"\n",
    "    Process hadith text to exclude matn and extract narrator IDs before it, with Arabic reshaping.\n",
    "    \n",
    "    Args:\n",
    "        hadith_text (str): Full hadith text with isnad and matn.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (str, list) - Processed text before matn (original right-to-left, reshaped), list of narrator IDs.\n",
    "    \"\"\"\n",
    "    # Parse the hadith text\n",
    "    soup = BeautifulSoup(hadith_text, 'html.parser')\n",
    "    \n",
    "    # Find the matn tag\n",
    "    matn_tag = soup.find('a', class_='matn')\n",
    "    if not matn_tag:\n",
    "        raise ValueError(\"No matn tag found in the hadith text.\")\n",
    "    \n",
    "    # Remove matn and everything after it\n",
    "    for element in matn_tag.find_all_next() + [matn_tag]:\n",
    "        element.decompose()\n",
    "    \n",
    "    # Extract narrator IDs in serial order (before matn)\n",
    "    narrator_tags = soup.find_all('a', class_='rawy')\n",
    "    narrator_ids = [tag['id'] for tag in narrator_tags]\n",
    "    \n",
    "    # Get the processed text and reshape it for original reading order (right-to-left)\n",
    "    processed_text = soup.get_text()\n",
    "    reshaped_text = arabic_reshaper.reshape(processed_text)  # Reshape without reversing\n",
    "    \n",
    "    return reshaped_text, narrator_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for idx in tqdm(range(len(df))):\n",
    "    book=df.iloc[idx,2]\n",
    "    hadith_id=df.iloc[idx,1]\n",
    "    data={}\n",
    "    with open(df.iloc[idx,0],\"r\") as f:\n",
    "        hadith_data=json.load(f)\n",
    "    if hadith_data[\"_source\"]['matn_with_tashkeel']:\n",
    "        processed_text, narrator_ids = process_hadith_text(hadith_data['_source'][\"hadith\"])\n",
    "        data[\"raw_isnad\"]=processed_text\n",
    "        data[\"grade\"]=hadith_data['_source'][\"rulings\"]\n",
    "        data[\"narrators\"]=narrator_ids\n",
    "        chain_path=df.iloc[idx,-1]\n",
    "        if type(chain_path)==str:\n",
    "            with open(chain_path,\"r\") as f:\n",
    "                chain_data=json.load(f)\n",
    "            data[\"chain\"]=chain_data[\"chain\"]\n",
    "        else:\n",
    "            data[\"chain\"]={}\n",
    "        save_book=os.path.join(save_data_dir,book)\n",
    "        os.makedirs(save_book,exist_ok=True)\n",
    "        save_json=os.path.join(save_book,hadith_id)\n",
    "        with open(save_json,\"w+\",encoding=\"utf-8\") as f:\n",
    "            json.dump(data,f,ensure_ascii=False,indent=2)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alminasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
